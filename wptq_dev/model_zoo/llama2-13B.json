{
    "_comment_": "re_ops: replace target ops in user's model, on_ops: replace all target class ops like linear conv2d..",
    "re_ops":{
        "layers": 40,
        "ops":
            {   
                "model.layers.id.self_attn.q_proj":{
                    "input":{
                        "quant_bit":"int-8",
                        "quant_policy":"per-layer",
                        "quant_strategy":"smooth"
                    },
                    "weight":{
                        "quant_bit":"int-8",
                        "quant_policy":"per-layer",
                        "quant_strategy":"smooth"
                    },
                    "bias":{
                        "quant_bit":"int-16",
                        "quant_policy":"per-layer",
                        "quant_strategy":null
                    },
                    "output":{
                        "quant_bit":"int-8",
                        "quant_policy":"per-channel",
                        "quant_strategy":null
                    }
                        
                },
                "model.layers.id.self_attn.k_proj":{
                    "input":{
                        "quant_bit":"int-8",
                        "quant_policy":"per-layer",
                        "quant_strategy":"smooth"
                    },
                    "output":{
                        "quant_bit":"int-8",
                        "quant_policy":"per-channel",
                        "quant_strategy":null
                    },
                    "weight":{
                        "quant_bit":"int-8",
                        "quant_policy":"per-layer",
                        "quant_strategy":"smooth"
                    },
                    "bias":{
                        "quant_bit":"int-16",
                        "quant_policy":"per-layer",
                        "quant_strategy":null
                    }
                },
                "model.layers.id.self_attn.v_proj":{
                    "input":{
                        "quant_bit":"int-8",
                        "quant_policy":"per-layer",
                        "quant_strategy":"smooth"
                    },
                    "output":{
                        "quant_bit":"int-8",
                        "quant_policy":"per-channel",
                        "quant_strategy":null
                    },
                    "weight":{
                        "quant_bit":"int-8",
                        "quant_policy":"per-layer",
                        "quant_strategy":"smooth"
                    },
                    "bias":{
                        "quant_bit":"int-16",
                        "quant_policy":"per-layer",
                        "quant_strategy":null
                    }
                },
                "model.layers.id.self_attn.o_proj":{
                    "input":{
                        "quant_bit":"int-8",
                        "quant_policy":"per-layer",
                        "quant_strategy":"smooth"
                    },
                    "output":{
                        "quant_bit":"int-8",
                        "quant_policy":"per-channel",
                        "quant_strategy":null
                    },
                    "weight":{
                        "quant_bit":"int-8",
                        "quant_policy":"per-layer",
                        "quant_strategy":"smooth"
                    },
                    "bias":{
                        "quant_bit":"int-16",
                        "quant_policy":"per-layer",
                        "quant_strategy":null
                    }
                },
                "model.layers.id.mlp.up_proj": {
                    "input":{
                        "quant_bit":"int-8",
                        "quant_policy":"per-layer",
                        "quant_strategy":null
                    },
                    "output":{
                        "quant_bit":"int-8",
                        "quant_policy":"per-channel",
                        "quant_strategy":null
                    },
                    "weight":{
                        "quant_bit":"int-8",
                        "quant_policy":"per-layer",
                        "quant_strategy":null
                    },
                    "bias":{
                        "quant_bit":"int-16",
                        "quant_policy":"per-layer",
                        "quant_strategy":null
                    }
                },
                "model.layers.id.mlp.gate_proj": {
                    "input":{
                        "quant_bit":"int-8",
                        "quant_policy":"per-layer",
                        "quant_strategy":null
                    },
                    "output":{
                        "quant_bit":"int-8",
                        "quant_policy":"per-channel",
                        "quant_strategy":null
                    },
                    "weight":{
                        "quant_bit":"int-8",
                        "quant_policy":"per-layer",
                        "quant_strategy":null
                    },
                    "bias":{
                        "quant_bit":"int-16",
                        "quant_policy":"per-layer",
                        "quant_strategy":null
                    }
                },
                "model.layers.id.mlp.down_proj":{
                    "input":{
                        "quant_bit":"int-8",
                        "quant_policy":"per-channel",
                        "quant_strategy":"smooth"
                    },
                    "output":{
                        "quant_bit":"int-8",
                        "quant_policy":"per-channel",
                        "quant_strategy":null
                    },
                    "weight":{
                        "quant_bit":"int-8",
                        "quant_policy":"per-channel",
                        "quant_strategy":"smooth"
                    },
                    "bias":{
                        "quant_bit":"int-16",
                        "quant_policy":"per-layer",
                        "quant_strategy":null
                    }
                }
            }               
    },
    "on_ops":null
}